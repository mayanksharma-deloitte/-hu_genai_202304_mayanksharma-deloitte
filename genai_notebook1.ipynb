{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aabcdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains import SimpleSequentialChain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544ad568",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624b3c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = OpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fa0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_breakdown = \"break down the user’s {instructions} into a series of steps in English\"\n",
    "\n",
    "mermaid_markup = \"dont't use brackets inside the markup;Generate a flowchart using valid mermaid.js syntax using this statement: {break_sentence}\"\n",
    "\n",
    "errorcount_change= \"Given the Mermaid markup, check for errors, and if any are found, rewrite the markup; otherwise, keep the original markup as is and give it as output: {markup}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eded3ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_breakdown_prompt = PromptTemplate(\n",
    "\n",
    "    template = step_breakdown,\n",
    "    input_variables =['instructions']\n",
    ")\n",
    "\n",
    "\n",
    "mermaid_markup_prompt = PromptTemplate(\n",
    "   \n",
    "    template = mermaid_markup,\n",
    "     input_variables =['break_sentence']\n",
    ")\n",
    "\n",
    "\n",
    "aftererror_markup_prompt = PromptTemplate(\n",
    "   \n",
    "     template = errorcount_change,\n",
    "     input_variables =['markup']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50ff3026",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_breakdown = LLMChain(llm=llm_model, prompt=step_breakdown_prompt,output_key='break_sentence',verbose=True)\n",
    "\n",
    "generate_markup = LLMChain(llm=llm_model, prompt=mermaid_markup_prompt,output_key='markup',verbose=True)\n",
    "\n",
    "generate_aftererror = LLMChain(llm=llm_model, prompt=aftererror_markup_prompt,output_key='final_markup',verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbfbbcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "\n",
    "             chains= [generate_breakdown,generate_markup,generate_aftererror],\n",
    "             verbose=True,\n",
    "   input_variables = ['instructions'],\n",
    "    output_variables = [\"break_sentence\",\"markup\",\"final_markup\"]\n",
    "          \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ead03dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mbreak down the user’s For christmas shopping, we first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop into a series of steps in English\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mdont't use brackets inside the markup;Generate a flowchart using valid mermaid.js syntax using this statement: \n",
      "\n",
      "1. Gather the necessary funds for Christmas shopping. \n",
      "2. Make a list of items to purchase. \n",
      "3. Decide which items to buy (i.e. iPhone, car, or laptop). \n",
      "4. Research the prices and features of the items. \n",
      "5. Visit stores or shop online to purchase the items. \n",
      "6. Complete payment for the items. \n",
      "7. Receive and unwrap the items.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the Mermaid markup, check for errors, and if any are found, rewrite the markup; otherwise, keep the original markup as is and give it as output: \n",
      "\n",
      "graph TD\n",
      "A[Gather the necessary funds for Christmas shopping] \n",
      "B[Make a list of items to purchase] \n",
      "C[Decide which items to buy] \n",
      "D[Research the prices and features of the items] \n",
      "E[Visit stores or shop online to purchase the items] \n",
      "F[Complete payment for the items] \n",
      "G[Receive and unwrap the items]\n",
      "\n",
      "A --> B\n",
      "B --> C\n",
      "C --> D\n",
      "D --> E\n",
      "E --> F\n",
      "F --> G\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Tokens Used: 652\n",
      "\tPrompt Tokens: 321\n",
      "\tCompletion Tokens: 331\n",
      "Successful Requests: 3\n",
      "Total Cost (USD): $0.01304\n"
     ]
    }
   ],
   "source": [
    "from langchain.callbacks import get_openai_callback\n",
    "with get_openai_callback() as cb:\n",
    "    response=overall_chain({\"instructions\":\"For christmas shopping, we first need to have some money. Then we go shopping, and then think what we want to buy. The things we can buy are iPhone, car or laptop\"})\n",
    "    print(cb)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80f64a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\ngraph TD\\nA[Gather the necessary funds for Christmas shopping] \\nB[Make a list of items to purchase] \\nC[Decide which items to buy] \\nD[Research the prices and features of the items] \\nE[Visit stores or shop online to purchase the items] \\nF[Complete payment for the items] \\nG[Receive and unwrap the items]\\n\\nA --> B\\nB --> C\\nC --> D\\nD --> E\\nE --> F\\nF --> G'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(response[\"markup\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8b40bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph TD\n",
      "A[Gather the necessary funds for Christmas shopping] \n",
      "B[Make a list of items to purchase] \n",
      "C[Decide which items to buy] \n",
      "D[Research the prices and features of the items] \n",
      "E[Visit stores or shop online to purchase the items] \n",
      "F[Complete payment for the items] \n",
      "G[Receive and unwrap the items]\n",
      "\n",
      "A --> B\n",
      "B --> C\n",
      "C --> D\n",
      "D --> E\n",
      "E --> F\n",
      "F --> G\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Find the index of the word \"graph\"\n",
    "start_index = response['markup'].index(\"graph\")\n",
    "\n",
    "# Extract everything from the start_index to the end of the string\n",
    "extracted_content = response['markup'][start_index:]\n",
    "\n",
    "print(extracted_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6651fa36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph TD\n",
      "A[Gather the necessary funds for Christmas shopping] \n",
      "B[Make a list of items to purchase] \n",
      "C[Decide which items to buy] \n",
      "D[Research the prices and features of the items] \n",
      "E[Visit stores or shop online to purchase the items] \n",
      "F[Complete payment for the items] \n",
      "G[Receive and unwrap the items]\n",
      "\n",
      "A --> B\n",
      "B --> C\n",
      "C --> D\n",
      "D --> E\n",
      "E --> F\n",
      "F --> G\n"
     ]
    }
   ],
   "source": [
    "print(extracted_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f6efcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://mermaid.ink/img/Z3JhcGggVEQKQVtHYXRoZXIgdGhlIG5lY2Vzc2FyeSBmdW5kcyBmb3IgQ2hyaXN0bWFzIHNob3BwaW5nXSAKQltNYWtlIGEgbGlzdCBvZiBpdGVtcyB0byBwdXJjaGFzZV0gCkNbRGVjaWRlIHdoaWNoIGl0ZW1zIHRvIGJ1eV0gCkRbUmVzZWFyY2ggdGhlIHByaWNlcyBhbmQgZmVhdHVyZXMgb2YgdGhlIGl0ZW1zXSAKRVtWaXNpdCBzdG9yZXMgb3Igc2hvcCBvbmxpbmUgdG8gcHVyY2hhc2UgdGhlIGl0ZW1zXSAKRltDb21wbGV0ZSBwYXltZW50IGZvciB0aGUgaXRlbXNdIApHW1JlY2VpdmUgYW5kIHVud3JhcCB0aGUgaXRlbXNdCgpBIC0tPiBCCkIgLS0+IEMKQyAtLT4gRApEIC0tPiBFCkUgLS0+IEYKRiAtLT4gRw==\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import base64\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mm(graph):\n",
    "  graphbytes = graph.encode(\"ascii\")\n",
    "  base64_bytes = base64.b64encode(graphbytes)\n",
    "  base64_string = base64_bytes.decode(\"ascii\")\n",
    "  display(Image(url=\"https://mermaid.ink/img/\" + base64_string))\n",
    "\n",
    "mm(\n",
    "extracted_content\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb7cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003feb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3f20c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
